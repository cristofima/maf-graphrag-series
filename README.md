# MAF + GraphRAG Series

Building Knowledge Graphs with Microsoft GraphRAG and Azure OpenAI.

## Series Overview

This repository contains the code for the **MAF + GraphRAG** article series, demonstrating enterprise-grade knowledge graph integration with Microsoft GraphRAG and Azure OpenAI.

| Part | Title | Status | Folder/Module |
|------|-------|--------|---------------|
| 1 | GraphRAG Fundamentals | ‚úÖ Complete | `core/` |
| 2 | GraphRAG MCP Server | ‚úÖ Complete | `mcp_server/` |
| 3 | Supervisor Agent Pattern | ‚úÖ Complete | `agents/` |
| 4 | Workflow Patterns | ‚è≥ Planned | `workflows/` |
| 5 | Agent Evaluation | ‚è≥ Planned | `evaluation/` |
| 6 | Human-in-the-Loop | ‚è≥ Planned | `middleware/` |
| 7 | Tool Registry | ‚è≥ Planned | `registry/` |
| 8 | Production Deployment | ‚è≥ Planned | `deploy/` |

## Part 1: GraphRAG Fundamentals

Learn the basics of Microsoft GraphRAG - transforming documents into knowledge graphs for complex reasoning.

### What You'll Learn

- Microsoft Research GraphRAG fundamentals
- Entity extraction from documents
- Relationship detection between entities
- Community detection (Leiden algorithm)
- Local vs Global search strategies

### Why GraphRAG (Not Standard RAG)?

| Question Type | Standard RAG | GraphRAG |
|---------------|-------------|----------|
| "Find similar documents" | ‚úÖ | ‚úÖ |
| "What is the relationship between X and Y?" | ‚ùå | ‚úÖ |
| "What are all the connections to Project Alpha?" | ‚ùå | ‚úÖ |
| "What themes span the entire organization?" | ‚ùå | ‚úÖ |

### Prerequisites

- **Python 3.10+** (tested with 3.11)
- **Poetry** for dependency management
- Azure OpenAI resource with:
  - GPT-4o deployment (for entity extraction and queries)
  - text-embedding-3-small deployment (for embeddings)
- Azure subscription

### Quick Start

```powershell
# Install Poetry (if not installed)
# Windows PowerShell:
(Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | py -

# Linux/macOS:
# curl -sSL https://install.python-poetry.org | python3 -

# Clone the repository
git clone https://github.com/cristofima/maf-graphrag-series.git
cd maf-graphrag-series

# RECOMMENDED: Configure Poetry to create .venv in project folder
poetry config virtualenvs.in-project true

# Install dependencies (Poetry creates virtual environment automatically)
poetry install

# Configure environment variables
cp .env.example .env
# Edit .env with your Azure OpenAI credentials

# Build the knowledge graph
poetry run python -m core.index

# Query the knowledge graph
poetry run python -m core.example "Who leads Project Alpha?"
poetry run python -m core.example "What are the main projects?" --type global
```

üí° **Note:** Poetry manages virtual environments automatically. You don't need to manually create `.venv` like with pip.

üìñ **Poetry Guide:** See [docs/poetry-guide.md](docs/poetry-guide.md) for detailed usage instructions.

### Using the Python API

The `core/` module provides a modern Python API for GraphRAG 3.0.x:

#### Building the Knowledge Graph

```python
import asyncio
from core import build_index

# Build knowledge graph from documents in input/documents/
results = asyncio.run(build_index())

for result in results:
    print(f"{result.workflow}: {result.errors or 'success'}")
```

Or use the CLI:

```powershell
poetry run python -m core.index
poetry run python -m core.index --resume  # Resume interrupted run
```

#### Querying the Knowledge Graph

```python
import asyncio
from core import load_all, local_search, global_search

# Load the knowledge graph
data = load_all()
print(f"Loaded: {data.entities.shape[0]} entities, {data.relationships.shape[0]} relationships")

# Entity-focused search
response, context = asyncio.run(local_search("Who leads Project Alpha?", data))
print(response)

# Thematic search
response, context = asyncio.run(global_search("What are the main projects?", data))
print(response)
```

Or use the CLI:

```powershell
poetry run python -m core.example "Who leads Project Alpha?"
poetry run python -m core.example "What are the main themes?" --type global
```

üìñ **API Documentation:** See [core/README.md](core/README.md) for full API reference.

## Part 2: GraphRAG MCP Server

Expose GraphRAG as an MCP (Model Context Protocol) server for AI agent integration.

### What You'll Learn

- Model Context Protocol (MCP) fundamentals
- FastMCP server implementation
- MCP tool design patterns
- Testing with MCP Inspector
- Agent-to-knowledge-graph communication

### Why MCP?

MCP enables agents to access external tools and data sources dynamically:

| Pattern | Description | Use Case |
|---------|-------------|----------|
| **Direct API calls** | Agent calls functions directly | Simple, single-agent scenarios |
| **MCP Tools** | Agent discovers and uses tools via protocol | Multi-agent, extensible systems |
| **Tool composition** | Multiple MCP servers, single agent | Enterprise knowledge access |

### Quick Start

```bash
# Install Part 2 dependencies
poetry install

# Option 1: Test in notebook (recommended, no server needed)
jupyter notebook notebooks/02_test_mcp_server.ipynb

# Option 2: Start MCP Server + use MCP Inspector
poetry run python run_mcp_server.py
npx @modelcontextprotocol/inspector   # Opens browser UI at http://localhost:6274
```

### Architecture

```
MCP Inspector / Client ‚Üí Streamable HTTP (/mcp) ‚Üí MCP Server (FastMCP) ‚Üí GraphRAG (core/)
```

### MCP Tools Exposed

| Tool | Purpose | Example Query |
|------|---------|---------------|
| `search_knowledge_graph` | Main entry point | Any question with search_type parameter |
| `local_search` | Entity-focused search | "Who leads Project Alpha?" |
| `global_search` | Thematic search | "What are the main projects?" |
| `list_entities` | Browse entities | "List all projects" |
| `get_entity` | Entity details | "Details about Dr. Emily Harrison" |

### Testing with MCP Inspector

The [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) is the recommended way to interact with the server during development:

```bash
# Terminal 1: Start MCP Server
poetry run python run_mcp_server.py

# Terminal 2: Launch MCP Inspector
npx @modelcontextprotocol/inspector
```

In the Inspector UI:
1. Set transport to **Streamable HTTP** and URL to `http://localhost:8011/mcp`
2. Click **Connect** ‚Üí Tools tab shows all 5 tools
3. Select a tool, fill in parameters, click **Run**

üìñ **MCP Documentation:** See [mcp_server/README.md](mcp_server/README.md) for complete documentation.

## Part 3: Supervisor Agent Pattern

Build the Knowledge Captain: a conversational agent that connects to the GraphRAG MCP server and automatically routes questions to the right search tool.

### What You'll Learn

- Microsoft Agent Framework fundamentals (1.0.0b260212)
- `MCPStreamableHTTPTool` for MCP server integration
- System prompt-based tool routing (GPT-4o decides, no code router)
- `AgentSession` for conversation memory across multiple turns
- MCP transport upgrade: SSE (`/sse`) ‚Üí Streamable HTTP (`/mcp`)
- Azure OpenAI client configuration with Azure Identity support

### Architecture

![Part 3 system architecture](docs/images/part3-architecture.png)

```mermaid
flowchart TD
    A["run_agent.py<br/>CLI entry point ¬∑ Rich"]
    B["agents/<br/>KnowledgeCaptainRunner ¬∑ GPT-4o<br/>MCPStreamableHTTPTool ¬∑ AgentSession"]
    C["mcp_server/<br/>FastMCP 0.2.0 ¬∑ port 8011<br/>local_search<br/>global_search<br/>list_entities ¬∑ get_entity"]
    D["core/<br/>GraphRAG 3.0.1<br/>147 entities<br/>263 relationships<br/>32 communities"]

    A --> B
    B -->|"Streamable HTTP /mcp"| C
    C -->|"Python API"| D
```

### Request Flow

![Knowledge Captain request flow ‚Äî two GPT-4o round trips per query](docs/images/agent-mcp-flow.png)

*Two round trips to Azure OpenAI per query: call 1 selects the tool, call 2 composes the answer.*

### Quick Start

```bash
# Install dependencies
poetry install

# Start MCP server (Terminal 1)
poetry run python run_mcp_server.py

# Interactive agent (Terminal 2)
poetry run python run_agent.py
```

### Key Pattern: System Prompt Routing

The agent uses its system prompt to decide which MCP tool to call‚Äîno separate routing logic needed:

| Question Type | Tool Selected | Example |
|---------------|---------------|---------|
| Entity-focused | `local_search` | "Who leads Project Alpha?" |
| Thematic | `global_search` | "What are the main projects?" |
| Entity details | `get_entity` | "Details about Dr. Emily Harrison" |

### Usage Example

```python
from agents import KnowledgeCaptainRunner

async with KnowledgeCaptainRunner() as runner:
    # First question
    response = await runner.ask("Who leads Project Alpha?")
    print(response.text)
    
    # Follow-up (has context from previous question)
    response = await runner.ask("What is their background?")
    print(response.text)
    
    # Reset conversation
    runner.clear_history()
```

### Microsoft Agent Framework 1.0.0b260212

Key patterns used:

| Pattern | Description |
|---------|-------------|
| `Agent` class | Core agent abstraction |
| `MCPStreamableHTTPTool` | Connect to MCP servers via Streamable HTTP |
| `AzureOpenAIChatClient` | Azure OpenAI wrapper (from `agent_framework.azure`) |
| `AgentSession` | Conversation memory across multiple turns |

üìñ **Agents Documentation:** See [agents/README.md](agents/README.md) for complete API reference.

### Knowledge Graph Statistics

After indexing the 10 sample documents, the knowledge graph contains:

| Metric | Count |
|--------|-------|
| **Entities** | 147 |
| **Relationships** | 263 |
| **Communities** | 32 |
| **Documents** | 10 |
| **Text Units** | 20 |

### Project Structure

```
maf-graphrag-series/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ pyproject.toml             # Poetry dependency management
‚îú‚îÄ‚îÄ poetry.lock                # Locked dependency versions
‚îú‚îÄ‚îÄ settings.yaml              # GraphRAG configuration
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ input/
‚îÇ   ‚îú‚îÄ‚îÄ README.md              # Document descriptions
‚îÇ   ‚îî‚îÄ‚îÄ documents/             # 10 sample interconnected documents
‚îÇ       ‚îú‚îÄ‚îÄ company_org.md
‚îÇ       ‚îú‚îÄ‚îÄ team_members.md
‚îÇ       ‚îú‚îÄ‚îÄ project_alpha.md
‚îÇ       ‚îú‚îÄ‚îÄ project_beta.md
‚îÇ       ‚îú‚îÄ‚îÄ technical_architecture.md
‚îÇ       ‚îú‚îÄ‚îÄ technology_stack.md
‚îÇ       ‚îú‚îÄ‚îÄ customers_partners.md
‚îÇ       ‚îú‚îÄ‚îÄ engineering_processes.md
‚îÇ       ‚îú‚îÄ‚îÄ incidents_postmortems.md
‚îÇ       ‚îî‚îÄ‚îÄ company_events_timeline.md
‚îú‚îÄ‚îÄ output/                    # Generated knowledge graph
‚îÇ   ‚îú‚îÄ‚îÄ *.parquet
‚îÇ   ‚îî‚îÄ‚îÄ lancedb/               # Vector store
‚îú‚îÄ‚îÄ core/                      # Part 1: Python API for GraphRAG 3.0.x
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configuration loading
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py         # Parquet file loading
‚îÇ   ‚îú‚îÄ‚îÄ indexer.py             # Build knowledge graph
‚îÇ   ‚îú‚îÄ‚îÄ search.py              # Async search functions
‚îÇ   ‚îú‚îÄ‚îÄ index.py               # CLI for indexing
‚îÇ   ‚îú‚îÄ‚îÄ example.py             # CLI for querying
‚îÇ   ‚îî‚îÄ‚îÄ README.md              # Module documentation
‚îú‚îÄ‚îÄ mcp_server/                # Part 2: MCP Server
‚îÇ   ‚îú‚îÄ‚îÄ server.py              # FastMCP server
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # MCP configuration
‚îÇ   ‚îú‚îÄ‚îÄ tools/                 # MCP tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ local_search.py    # Entity-focused search (with source traceability)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ global_search.py   # Thematic search (community reports only)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entity_query.py    # Entity lookup
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ source_resolver.py # Resolves text unit IDs ‚Üí document titles
‚îÇ   ‚îî‚îÄ‚îÄ README.md              # MCP documentation
‚îú‚îÄ‚îÄ agents/                    # Part 3: Conversational Agent
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # Public API re-exports
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Agent configuration (Azure OpenAI + MCP URL)
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py             # Knowledge Captain system prompt
‚îÇ   ‚îú‚îÄ‚îÄ supervisor.py          # KnowledgeCaptainRunner + MCPStreamableHTTPTool
‚îÇ   ‚îî‚îÄ‚îÄ README.md              # Agents documentation
‚îú‚îÄ‚îÄ run_agent.py               # Interactive agent CLI
‚îú‚îÄ‚îÄ run_mcp_server.py          # Start MCP server
‚îú‚îÄ‚îÄ prompts/                   # Custom prompt templates
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ poetry-guide.md                    # Poetry usage guide
‚îÇ   ‚îú‚îÄ‚îÄ query-guide.md                     # Query reference
‚îÇ   ‚îú‚îÄ‚îÄ qa-examples.md                     # Q&A examples with responses
‚îÇ   ‚îú‚îÄ‚îÄ lessons-learned.md                 # Deployment insights
‚îÇ   ‚îî‚îÄ‚îÄ part...-notes.md                   # Implementation notes per part
‚îî‚îÄ‚îÄ notebooks/
    ‚îú‚îÄ‚îÄ 01_explore_graph.ipynb      # Part 1: Graph visualization
    ‚îî‚îÄ‚îÄ 02_test_mcp_server.ipynb    # Part 2: MCP server testing
```

## Sample Q&A Results

### Local Search (Entity-Focused)

**Question:** "Who resolved the GraphRAG index corruption incident and what was the root cause?"

**Answer:**
> The GraphRAG index corruption incident was resolved through the collaborative efforts of Sophia Lee, Priya Patel, Dr. Emily Harrison, and David Kumar. The root cause was identified as an interrupted indexing job during an Azure Container Apps scaling event, which left the graph in an inconsistent state. The resolution involved implementing a full re-index with validation checks and atomic swap procedures.

**Question:** "Who leads Project Alpha and what is their background?"

**Answer:**
> Dr. Emily Harrison leads Project Alpha at TechVenture Inc. She holds a Ph.D. in Quantum Computing from MIT and has 15 years of experience in advanced computing research. Under her leadership, Project Alpha is developing a next-generation quantum-classical hybrid processor that has achieved 99.7% gate fidelity.

### Global Search (Thematic)

**Question:** "What are the main initiatives at TechVenture?"

**Answer:**
> TechVenture Inc. is pursuing major strategic initiatives:
> 1. **Project Alpha** - Quantum computing research led by Dr. Emily Harrison (Phase 4 - GA Preparation)
> 2. **Project Beta** - AI/ML platform for healthcare applications (Active production with enterprise customers)
>
> These projects share resources through cross-functional collaboration, with teams spanning Research, Engineering, and Infrastructure departments.

See [docs/qa-examples.md](docs/qa-examples.md) for more examples.

## Azure AI Services Used

| Service | Purpose | Model/Version |
|---------|---------|---------------|
| **Azure OpenAI** | Entity extraction, queries | GPT-4o |
| **Azure OpenAI** | Document embeddings | text-embedding-3-small |
| **Agent Framework** | Multi-agent orchestration | 1.0.0b260212 |

## Key Files

| File | Description |
|------|-------------|
| `settings.yaml` | GraphRAG configuration (LLM, embeddings, storage) |
| `core/` | Python API module for indexing, querying, and data access |
| `.env` | Azure OpenAI credentials (create from .env.example) |

## License

MIT License - See [LICENSE](LICENSE) for details.

## Author

Cristopher Coronado
