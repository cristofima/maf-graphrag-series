{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4435796",
   "metadata": {},
   "source": [
    "# GraphRAG MCP Server Testing\n",
    "\n",
    "This notebook tests the GraphRAG MCP tools directly and via the HTTP server.\n",
    "\n",
    "**Prerequisites:**\n",
    "1. Knowledge graph indexed: `poetry run python -m core.index`\n",
    "2. Azure OpenAI configured in `.env`\n",
    "\n",
    "**Optional (for HTTP tests):**\n",
    "\n",
    "3. MCP server running: `poetry run python run_mcp_server.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a9e83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration Check:\n",
      "   Azure OpenAI Endpoint: https://maf-graphrag-openai-5woawz.openai.azure.com/\n",
      "   Chat Deployment: gpt-4o\n",
      "   Embedding Deployment: text-embedding-3-small\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify configuration\n",
    "print(\"Configuration Check:\")\n",
    "print(f\"   Azure OpenAI Endpoint: {os.getenv('AZURE_OPENAI_ENDPOINT')}\")\n",
    "print(f\"   Chat Deployment: {os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT', 'gpt-4o')}\")\n",
    "print(f\"   Embedding Deployment: {os.getenv('AZURE_OPENAI_EMBEDDING_DEPLOYMENT', 'text-embedding-3-small')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3317ba",
   "metadata": {},
   "source": [
    "## 1. Test MCP Server Connection (optional)\n",
    "\n",
    "Only needed if you started the MCP server with `poetry run python run_mcp_server.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ea06bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ MCP Server not running!\n",
      "   Start it with: poetry run python run_mcp_server.py\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "\n",
    "# Test MCP server health\n",
    "async def test_mcp_server():\n",
    "    try:\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.get(\"http://localhost:8011/health\", timeout=5.0)\n",
    "            print(f\"✅ MCP Server Status: {response.status_code}\")\n",
    "            print(f\"   Response: {response.text}\")\n",
    "    except httpx.ConnectError:\n",
    "        print(\"❌ MCP Server not running!\")\n",
    "        print(\"   Start it with: poetry run python run_mcp_server.py\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error: {e}\")\n",
    "\n",
    "await test_mcp_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e9dc7",
   "metadata": {},
   "source": [
    "## 2. Test Entity Query Tool\n",
    "\n",
    "List and search entities directly (no server needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd41cc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 person entities (showing 5):\n",
      "\n",
      "  - DR. EMILY HARRISON (PERSON)\n",
      "  - DAVID KUMAR (PERSON)\n",
      "  - AMANDA FOSTER (PERSON)\n",
      "  - DR. JAMES MITCHELL (PERSON)\n",
      "  - SOPHIA LEE (PERSON)\n",
      "\n",
      "Searching for 'Emily Harrison':\n",
      "  - DR. EMILY HARRISON: Dr. Emily Harrison is a distinguished figure in the realm of artificial intelligence and machine lea...\n",
      "  - EMILY HARRISON: Dr. Emily Harrison serves as the Vice President of AI Research at TechVenture Inc., where she plays ...\n"
     ]
    }
   ],
   "source": [
    "from mcp_server.tools.entity_query import entity_query_tool\n",
    "\n",
    "# List entities by type\n",
    "result = await entity_query_tool(entity_type=\"person\", limit=5)\n",
    "\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "else:\n",
    "    print(f\"Found {result['total_found']} person entities (showing {result['returned']}):\\n\")\n",
    "    for entity in result[\"entities\"]:\n",
    "        print(f\"  - {entity['name']} ({entity['type']})\")\n",
    "\n",
    "# Search by name\n",
    "print(f\"\\nSearching for 'Emily Harrison':\")\n",
    "result = await entity_query_tool(entity_name=\"Emily Harrison\")\n",
    "if \"error\" not in result:\n",
    "    for entity in result[\"entities\"]:\n",
    "        print(f\"  - {entity['name']}: {entity['description'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8b79e3",
   "metadata": {},
   "source": [
    "## 3. Test Local Search (Entity-Focused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3ddf2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Query: Who leads Project Alpha?\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:30:04 - LiteLLM:INFO\u001b[0m: utils.py:1629 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/26 13:30:04] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Wrapper: Completed Call, calling success_handler                         <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#1629\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1629</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/26 13:30:04]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Wrapper: Completed Call, calling success_handler                         \u001b]8;id=487587;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=296017;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#1629\u001b\\\u001b[2m1629\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/26 13:30:05] </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> Reached token limit - reverting to previous context state         <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">mixed_context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py#447\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">447</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/26 13:30:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m Reached token limit - reverting to previous context state         \u001b]8;id=26715;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py\u001b\\\u001b[2mmixed_context.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=750809;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py#447\u001b\\\u001b[2m447\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:30:05 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=142715;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=844202;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Project Alpha is led by Dr. Emily Harrison, who serves as the Project Lead. She is the head of the AI Research Department at TechVenture Inc. and is responsible for overseeing the project's strategy and research direction. Dr. Harrison collaborates closely with various team members, including Dr. James Mitchell, Sophia Lee, and Alex Turner, on aspects such as machine learning model integration and knowledge graph construction [Data: Sources (0); Entities (1); Reports (19); Entities (13)]. \n",
      "\n",
      "The ...\n",
      "\n",
      "Context: {'entities_used': 0, 'relationships_used': 0, 'reports_used': 0}\n",
      "\n",
      "======================================================================\n",
      "Query: Who resolved the GraphRAG index corruption incident?\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:30:09 - LiteLLM:INFO\u001b[0m: utils.py:1629 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/26 13:30:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Wrapper: Completed Call, calling success_handler                         <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#1629\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1629</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/26 13:30:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Wrapper: Completed Call, calling success_handler                         \u001b]8;id=794354;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=810063;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#1629\u001b\\\u001b[2m1629\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:30:09 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=489612;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=802932;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The GraphRAG Index Corruption incident was primarily resolved through the efforts of several key individuals at TechVenture Inc. Sophia Lee played a significant role by identifying the corrupt community reports in the GraphRAG output, which were traced to an interrupted indexing job from the previous night [Data: Relationships (238), Sources (17)]. Dr. Emily Harrison noticed the false responses generated during the incident and confirmed that a partial index was being incorrectly served [Data: R...\n",
      "\n",
      "Context: {'entities_used': 0, 'relationships_used': 0, 'reports_used': 0}\n",
      "\n",
      "======================================================================\n",
      "Query: What technologies are used in Project Beta?\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:30:12 - LiteLLM:INFO\u001b[0m: utils.py:1629 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/26 13:30:12] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Wrapper: Completed Call, calling success_handler                         <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#1629\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1629</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/26 13:30:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Wrapper: Completed Call, calling success_handler                         \u001b]8;id=67804;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=51754;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#1629\u001b\\\u001b[2m1629\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> Reached token limit - reverting to previous context state         <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">mixed_context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py#447\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">447</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m Reached token limit - reverting to previous context state         \u001b]8;id=185418;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py\u001b\\\u001b[2mmixed_context.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=329624;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py#447\u001b\\\u001b[2m447\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:30:12 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=398829;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=156048;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">54.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m54.000000\u001b[0m seconds        \u001b]8;id=376923;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=104659;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ## Technologies Used in Project Beta\n",
      "\n",
      "Project Beta, a major initiative by TechVenture Inc., is built as an AI-powered healthcare analytics platform and utilizes a sophisticated technology stack to ensure compliance and efficiency.\n",
      "\n",
      "### Core Components and Technologies\n",
      "\n",
      "1. **Data Processing and Ingestion:**\n",
      "   - **Azure Data Factory and Databricks**: These tools are used for processing and integration with hospital electronic health record (EHR) systems such as Epic and Cerner, utilizing HL7 FHIR...\n",
      "\n",
      "Context: {'entities_used': 0, 'relationships_used': 0, 'reports_used': 0}\n"
     ]
    }
   ],
   "source": [
    "from mcp_server.tools.local_search import local_search_tool\n",
    "\n",
    "queries = [\n",
    "    \"Who leads Project Alpha?\",\n",
    "    \"Who resolved the GraphRAG index corruption incident?\",\n",
    "    \"What technologies are used in Project Beta?\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    result = await local_search_tool(query)\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "    else:\n",
    "        print(f\"Answer: {result['answer'][:500]}...\")\n",
    "        print(f\"\\nContext: {result['context']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5335fa",
   "metadata": {},
   "source": [
    "## 4. Test Global Search (Thematic)\n",
    "\n",
    "**Note:** Global search uses map-reduce across all communities, making many parallel LLM calls. May be slow or hit rate limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a62f92d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:17 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the main projects at TechVenture Inc?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:17 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/26 13:31:17] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/26 13:31:17]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=666192;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=659730;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:17 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:17 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=798541;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=969805;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:17 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:17 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=506708;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=50261;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:17 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:17 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=579802;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=4144;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=811416;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=91146;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=545916;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=239275;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=696788;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=480604;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=816642;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=866172;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/26 13:31:19] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/26 13:31:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=911333;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=101301;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=729142;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=415680;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=77984;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=464443;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=164579;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=113052;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=618185;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=667265;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=642712;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=818076;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=397300;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=237604;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=645237;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=174116;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=627974;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=534847;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=939107;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=144155;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:31:19 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=780448;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=127177;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=647735;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=582741;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=456049;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=249341;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=126459;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=766659;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=973700;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=222565;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=223005;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=746162;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=953382;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=799156;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=881668;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=269133;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=295976;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=898862;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=505972;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=510678;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=413918;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=560281;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=967349;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=87258;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/26 13:31:20] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/26 13:31:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=645948;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=404737;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=640776;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=460013;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=747406;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=629616;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=897820;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=497026;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=727273;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=351141;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=173039;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=922098;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=254221;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=882875;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=967567;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=273808;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=684896;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=17975;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=544045;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=927325;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=279314;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=851423;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=597199;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=4896;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=52603;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=189940;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=675690;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=201306;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:32:09 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:32:09 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/26 13:32:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/26 13:32:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=937216;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=961498;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=886299;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=907479;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.000000</span> seconds         <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m9.000000\u001b[0m seconds         \u001b]8;id=169416;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=119370;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9.000000</span> seconds         <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m9.000000\u001b[0m seconds         \u001b]8;id=161976;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=7291;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:32:20 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n",
      "\u001b[92m13:32:20 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/26 13:32:20] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/26 13:32:20]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=91285;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=308205;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=518140;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=389498;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Retrying request to <span style=\"color: #800080; text-decoration-color: #800080\">/chat/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">completions</span> in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">47.000000</span> seconds        <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_base_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1693</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Retrying request to \u001b[35m/chat/\u001b[0m\u001b[95mcompletions\u001b[0m in \u001b[1;36m47.000000\u001b[0m seconds        \u001b]8;id=721946;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py\u001b\\\u001b[2m_base_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=210651;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\openai\\_base_client.py#1693\u001b\\\u001b[2m1693\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:33:11 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/26 13:33:11] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/26 13:33:11]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=831665;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=417593;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "TechVenture Inc. is actively engaged in several pioneering projects, each with distinct objectives and technological innovations. Here is an overview of the main projects:\n",
      "\n",
      "### Project Alpha\n",
      "Project Alpha is a flagship initiative at TechVenture Inc., focusing on the transformation and enhancement of the company's technological infrastructure. This project emphasizes the transition toward cloud services, utilizing Microsoft Azure to offer robust and scalable solutions [Data: Reports (10, 9, 29)]. Jennifer Park leads the project, steering efforts on infrastructure management and scalability [Data: Reports (10)]. Priya Patel is integral to the search infrastructure, exploring Rust for potential performance gains [Data: Reports (18)]. Mark Johnson's contributions focus on API development and frontend integration, further solidifying the project's impact [Data: Reports (16)]. Furthermore, Project Alpha aims to revolutionize AI technology through multi-modal interactions, positioning TechVenture as a leader in the tech industry [Data: Reports (0, 9, 19, 12, 15)]. The strategic partnership with Microsoft, which involves Azure credits and technical support, significantly enhances Project Alpha's capabilities [Data: Reports (9, 25)].\n",
      "\n",
      "### Project Beta\n",
      "Project Beta is another key undertaking at TechVenture, targeting the healthcare sector. It seeks to innovate healthcare analytics by deploying AI-driven tools to cut down hospital readmission rates, thereby improving healthcare outcomes [Data: Reports (3, 0, 12, 26)]. TechVenture implements Azure Confidential Computing within this project to ensure data privacy and security, underlining their commitment to safeguarding sensitive health information while addressing industry challenges [Data: Reports (0)].\n",
      "\n",
      "### Customer Portal Project\n",
      "TechVenture Inc. is also working on the Customer Portal project, which is pivotal in advancing customer-facing technologies. The initiative focuses on product development and the implementation of novel features. Led by David Kumar in Product Engineering, this project exemplifies TechVenture's dedication to delivering enhanced experiences for its customers [Data: Reports (17)].\n",
      "\n",
      "These projects reflect TechVenture Inc.'s ongoing commitment to technological advancement across various sectors, ensuring they remain at the forefront of innovation and customer service.\n",
      "\n",
      "Context: {'communities_analyzed': 0}\n"
     ]
    }
   ],
   "source": [
    "from mcp_server.tools.global_search import global_search_tool\n",
    "\n",
    "query = \"What are the main projects at TechVenture Inc?\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "result = await global_search_tool(query)\n",
    "if \"error\" in result:\n",
    "    print(f\"Error: {result['error']}\")\n",
    "    if \"details\" in result:\n",
    "        print(f\"Details: {result['details']}\")\n",
    "else:\n",
    "    print(f\"Answer:\\n{result['answer']}\")\n",
    "    print(f\"\\nContext: {result['context']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b84724",
   "metadata": {},
   "source": [
    "## 5. Cross-Document Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6243406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Query: Who are the customers of Project Beta and what incidents affected them?\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:35:22 - LiteLLM:INFO\u001b[0m: utils.py:1629 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/26 13:35:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Wrapper: Completed Call, calling success_handler                         <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#1629\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1629</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/26 13:35:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Wrapper: Completed Call, calling success_handler                         \u001b]8;id=679800;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=391272;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#1629\u001b\\\u001b[2m1629\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> Reached token limit - reverting to previous context state         <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">mixed_context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py#447\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">447</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m Reached token limit - reverting to previous context state         \u001b]8;id=642949;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py\u001b\\\u001b[2mmixed_context.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=431511;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py#447\u001b\\\u001b[2m447\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:35:22 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=172700;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=638064;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ### Customers of Project Beta\n",
      "\n",
      "Project Beta, an AI-powered healthcare analytics platform developed by TechVenture Inc., serves a variety of healthcare providers and hospital networks, focusing on improving healthcare outcomes through advanced analytics and predictive models [Data: Sources (2); Entities (22), Reports (19)]. Notable customers include:\n",
      "\n",
      "1. **Meridian Healthcare System**: This is a flagship client of Project Beta, consisting of an eight-hospital network. They utilize Project Beta to...\n",
      "\n",
      "======================================================================\n",
      "Query: What is the connection between David Kumar, Sophia Lee, and the GraphRAG incident?\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:35:31 - LiteLLM:INFO\u001b[0m: utils.py:1629 - Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02/07/26 13:35:31] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Wrapper: Completed Call, calling success_handler                         <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#1629\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1629</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02/07/26 13:35:31]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Wrapper: Completed Call, calling success_handler                         \u001b]8;id=700834;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=555217;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#1629\u001b\\\u001b[2m1629\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> Reached token limit - reverting to previous context state         <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">mixed_context.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py#447\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">447</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[33mWARNING \u001b[0m Reached token limit - reverting to previous context state         \u001b]8;id=441870;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py\u001b\\\u001b[2mmixed_context.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=57935;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\graphrag\\query\\structured_search\\local_search\\mixed_context.py#447\u001b\\\u001b[2m447\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m13:35:31 - LiteLLM:INFO\u001b[0m: utils.py:3887 - \n",
      "LiteLLM completion() model= gpt-4o; provider = azure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span>                                                                          <a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3887</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         LiteLLM <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">completion</span><span style=\"font-weight: bold\">()</span> <span style=\"color: #808000; text-decoration-color: #808000\">model</span>= gpt-4o; provider = azure                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m                                                                          \u001b]8;id=964185;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py\u001b\\\u001b[2mutils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=188296;file://c:\\Framework_Projects\\AI-Ideas\\maf-graphrag-series\\.venv\\Lib\\site-packages\\litellm\\utils.py#3887\u001b\\\u001b[2m3887\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         LiteLLM \u001b[1;35mcompletion\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m \u001b[33mmodel\u001b[0m= gpt-4o; provider = azure                     \u001b[2m             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: # Connection Between David Kumar, Sophia Lee, and the GraphRAG Incident\n",
      "\n",
      "TechVenture Inc. experienced a critical incident involving GraphRAG, which is part of its AI infrastructure. This incident, termed the **GraphRAG Index Corruption**, was a significant event, affecting the company's AI-driven services and required skilled intervention for resolution.\n",
      "\n",
      "## Incident Overview\n",
      "\n",
      "The GraphRAG Index Corruption occurred on March 18, 2024, and was categorized as a SEV-2 incident, impacting the Project...\n"
     ]
    }
   ],
   "source": [
    "complex_queries = [\n",
    "    \"Who are the customers of Project Beta and what incidents affected them?\",\n",
    "    \"What is the connection between David Kumar, Sophia Lee, and the GraphRAG incident?\",\n",
    "]\n",
    "\n",
    "for query in complex_queries:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "    result = await local_search_tool(query)\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error: {result['error']}\")\n",
    "    else:\n",
    "        print(f\"Answer: {result['answer'][:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26391088",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. MCP Server connectivity check\n",
    "2. Entity query tool (list/search entities)\n",
    "3. Local search (entity-focused queries)\n",
    "4. Global search (thematic/community queries)\n",
    "5. Cross-document reasoning\n",
    "\n",
    "**Testing via HTTP:** Use [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) for interactive server testing:\n",
    "```bash\n",
    "npx @modelcontextprotocol/inspector\n",
    "```\n",
    "\n",
    "**Next Steps:**\n",
    "- Part 3: Supervisor Agent Pattern (agent-framework integration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
